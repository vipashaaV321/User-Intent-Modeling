{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP18i+ypQPCiurcesmLT4aN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipashaaV321/User-Intent-Modeling/blob/main/failed_approaches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4E2NCPNDwH-",
        "outputId": "e26ebde8-27f4-4e2a-d5cb-88cdaabdc20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.14.0\n",
            "Uninstalling tensorflow-2.14.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.14.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "Y\n",
            "  Successfully uninstalled tensorflow-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED_774duDwPF",
        "outputId": "7945e44a-0f71-43c5-9645-bc3001238daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.decomposition import NMF"
      ],
      "metadata": {
        "id": "g1kTL08u-s5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## extracting data\n",
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "ZipFile(\"movielens.zip\", \"r\").extractall()"
      ],
      "metadata": {
        "id": "YvftTOV3-s5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv(\n",
        "    \"ml-1m/ratings.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"item_id\", \"rating\", \"unix_timestamp\"],\n",
        ")\n",
        "ratings.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "286a8f71-0307-48b1-a0c4-f47a7a429cc5",
        "id": "NSTvagtG-s5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-b72da1ac23ec>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  ratings = pd.read_csv(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rating  unix_timestamp\n",
              "0        1     1193       5       978300760\n",
              "1        1      661       3       978302109\n",
              "2        1      914       3       978301968\n",
              "3        1     3408       4       978300275\n",
              "4        1     2355       5       978824291"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d8cf788-518a-4442-875f-69fa109d62c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>unix_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d8cf788-518a-4442-875f-69fa109d62c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d8cf788-518a-4442-875f-69fa109d62c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d8cf788-518a-4442-875f-69fa109d62c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c44e51ba-3629-4460-a00e-a5a722f417ae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c44e51ba-3629-4460-a00e-a5a722f417ae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c44e51ba-3629-4460-a00e-a5a722f417ae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-iPU6rW1O6JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = ratings.drop(\"unix_timestamp\", axis=1)"
      ],
      "metadata": {
        "id": "qWdhriu0D9Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SVoETYdvECkL",
        "outputId": "f0c28722-ce67-458f-85e4-cfa7e4090eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rating\n",
              "0        1     1193       5\n",
              "1        1      661       3\n",
              "2        1      914       3\n",
              "3        1     3408       4\n",
              "4        1     2355       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ef89491-1c91-48fe-9599-52c532f30989\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ef89491-1c91-48fe-9599-52c532f30989')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ef89491-1c91-48fe-9599-52c532f30989 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ef89491-1c91-48fe-9599-52c532f30989');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dbe74bdc-3292-4d8f-a685-941ad486cbda\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dbe74bdc-3292-4d8f-a685-941ad486cbda')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dbe74bdc-3292-4d8f-a685-941ad486cbda button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RneY6WxbDs3G"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prepare user profiles and item importance weights\n",
        "user_profiles = {}\n",
        "item_importance_weights = tf.Variable(tf.ones(len(ratings['item_id'].unique())))\n",
        "\n",
        "for user_id, item_id, rating in ratings.values:\n",
        "    if user_id not in user_profiles:\n",
        "        user_profiles[user_id] = {}\n",
        "    user_profiles[user_id][item_id] = rating"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " tf.experimental.numpy.experimental_enable_numpy_behavior()"
      ],
      "metadata": {
        "id": "Hkx-rsqnX64y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define attention modeling with feedback-based neural network\n",
        "def attention_model(user_profile, item_ids, item_importance_weights):\n",
        "\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "    # Convert user profile to a tensor\n",
        "    print(\"Inside Attention Modeling\")\n",
        "    user_profile_values = list(user_profile.values())\n",
        "    print(\"User Profile Values\",user_profile_values)\n",
        "    user_profile_tensor = tf.convert_to_tensor(user_profile_values)\n",
        "    user_profile_tensor= tf.cast(user_profile_tensor, tf.float32)\n",
        "    user_profile_tensor = tf.expand_dims(user_profile_tensor, axis=0)\n",
        "    print(\"User Profile Tensor\",user_profile_tensor)\n",
        "    # user_profile_tensor = tf.eval(user_profile_tensor)\n",
        "    print(user_profile_tensor.shape)\n",
        "    # Embed item IDs\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(input_dim=len(ratings['item_id'].unique()), output_dim=16)\n",
        "    item_embeddings = item_embedding_layer(item_ids)\n",
        "    item_embeddings = tf.transpose(item_embeddings)\n",
        "\n",
        "    print(\"Item EMb\",item_embeddings)\n",
        "    print(item_embeddings.shape)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    attention_scores = tf.matmul(user_profile_tensor, item_embeddings.T)\n",
        "    print(\"attn:\",attention_scores)\n",
        "    attention_scores = tf.nn.softmax(attention_scores)\n",
        "    print(\"soft att\",attention_scores)\n",
        "\n",
        "    # Define item importance weights with explicit data type\n",
        "    item_importance_weights = tf.Variable(tf.ones(len(ratings['item_id'].unique()), dtype=tf.float32))\n",
        "\n",
        "    # Convert item importance weights to float32 data type\n",
        "    item_importance_weights_float32 = tf.cast(item_importance_weights, tf.float32)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    attention_scores = tf.nn.softmax(item_importance_weights_float32)\n",
        "\n",
        "  # Apply item importance weights\n",
        "    weighted_attention_scores = attention_scores * item_importance_weights_float32\n",
        "\n",
        "\n",
        "    # Convert item importance weights to float32 data type\n",
        "    # item_importance_weights_float32 = tf.cast(item_importance_weights, tf.float32)\n",
        "\n",
        "    # # Calculate weighted attention scores\n",
        "    # weighted_attention_scores = attention_scores * item_importance_weights_float32\n",
        "    # Apply item importance weights\n",
        "    # weighted_attention_scores = attention_scores * item_importance_weights\n",
        "    print(\"w att:\",weighted_attention_scores)\n",
        "\n",
        "    return weighted_attention_scores"
      ],
      "metadata": {
        "id": "0ZKJCYdoEOBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define multi-round recommendation function\n",
        "def multi_round_recommendation(user_id, num_recommendations, num_rounds):\n",
        "    print(\"inside multround\")\n",
        "    recommendations = []\n",
        "\n",
        "    is_finished = False\n",
        "    for _ in range(num_rounds):\n",
        "        # Get user profile for current round\n",
        "        current_user_profile = user_profiles[user_id]\n",
        "        print(user_profiles[user_id])\n",
        "        print(current_user_profile)\n",
        "\n",
        "        # Recommend items based on attention model\n",
        "        item_ids = np.array(list(current_user_profile.keys()))\n",
        "        item_ratings = np.array(list(current_user_profile.values()))\n",
        "\n",
        "        print(\"itemID\",item_ids)\n",
        "        print(\"itemRatings\",item_ratings)\n",
        "\n",
        "\n",
        "        # Update item importance weights using neural network\n",
        "        with tf.GradientTape() as tape:\n",
        "            print(\"in a loop of item importance updation\")\n",
        "            attention_scores = attention_model(current_user_profile, item_ids, item_importance_weights)\n",
        "            print(\"Attention Scores from a func\")\n",
        "            print(attention_scores)\n",
        "            print(attention_scores.dtype)\n",
        "            print(item_importance_weights)\n",
        "            item_importance_gradients = tape.gradient(attention_scores, item_importance_weights)\n",
        "            print(\"Grad\")\n",
        "            print(item_importance_gradients)\n",
        "\n",
        "        # Update item importance weights based on feedback\n",
        "        for item_id, item_rating, item_importance_gradient in zip(item_ids, item_ratings, item_importance_gradients):\n",
        "            item_importance_weights.assign_sub(item_importance_gradient * item_rating)\n",
        "\n",
        "        # Recommend top n items\n",
        "        recommended_item_ids = item_ids[np.argsort(attention_scores)[-num_recommendations:]]\n",
        "\n",
        "        print(\"Recommend: \",recommended_item_ids)\n",
        "\n",
        "        # Print recommended items\n",
        "        print(\"Recommended items:\")\n",
        "        for item_id in recommended_item_ids:\n",
        "            print(item_id)\n",
        "\n",
        "        # Get user feedback\n",
        "        selected_item_id = input(\"Select an item (or type 'end' to finish): \")\n",
        "\n",
        "        if selected_item_id == 'end':\n",
        "            is_finished = True\n",
        "            break\n",
        "\n",
        "        # Update user profile with new feedback\n",
        "        current_user_profile[selected_item_id] = 1\n",
        "\n",
        "        # Add recommended items to the list\n",
        "        recommendations.extend(recommended_item_ids)\n",
        "\n",
        "    if not is_finished:\n",
        "        print(\"Recommendations:\")\n",
        "        for item_id in recommendations:\n",
        "            print(item_id)\n"
      ],
      "metadata": {
        "id": "OrlAZOgGEGZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "user_id = 1\n",
        "num_recommendations = 10\n",
        "num_rounds = 3\n",
        "\n",
        "multi_round_recommendation(user_id, num_recommendations, num_rounds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "id": "TYb8R-0WEMV5",
        "outputId": "389dd0d4-eb12-4d8f-90b9-b2f30f1ea029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside multround\n",
            "{1193: 5, 661: 3, 914: 3, 3408: 4, 2355: 5, 1197: 3, 1287: 5, 2804: 5, 594: 4, 919: 4, 595: 5, 938: 4, 2398: 4, 2918: 4, 1035: 5, 2791: 4, 2687: 3, 2018: 4, 3105: 5, 2797: 4, 2321: 3, 720: 3, 1270: 5, 527: 5, 2340: 3, 48: 5, 1097: 4, 1721: 4, 1545: 4, 745: 3, 2294: 4, 3186: 4, 1566: 4, 588: 4, 1907: 4, 783: 4, 1836: 5, 1022: 5, 2762: 4, 150: 5, 1: 5, 1961: 5, 1962: 4, 2692: 4, 260: 4, 1028: 5, 1029: 5, 1207: 4, 2028: 5, 531: 4, 3114: 4, 608: 4, 1246: 4}\n",
            "{1193: 5, 661: 3, 914: 3, 3408: 4, 2355: 5, 1197: 3, 1287: 5, 2804: 5, 594: 4, 919: 4, 595: 5, 938: 4, 2398: 4, 2918: 4, 1035: 5, 2791: 4, 2687: 3, 2018: 4, 3105: 5, 2797: 4, 2321: 3, 720: 3, 1270: 5, 527: 5, 2340: 3, 48: 5, 1097: 4, 1721: 4, 1545: 4, 745: 3, 2294: 4, 3186: 4, 1566: 4, 588: 4, 1907: 4, 783: 4, 1836: 5, 1022: 5, 2762: 4, 150: 5, 1: 5, 1961: 5, 1962: 4, 2692: 4, 260: 4, 1028: 5, 1029: 5, 1207: 4, 2028: 5, 531: 4, 3114: 4, 608: 4, 1246: 4}\n",
            "itemID [1193  661  914 3408 2355 1197 1287 2804  594  919  595  938 2398 2918\n",
            " 1035 2791 2687 2018 3105 2797 2321  720 1270  527 2340   48 1097 1721\n",
            " 1545  745 2294 3186 1566  588 1907  783 1836 1022 2762  150    1 1961\n",
            " 1962 2692  260 1028 1029 1207 2028  531 3114  608 1246]\n",
            "itemRatings [5 3 3 4 5 3 5 5 4 4 5 4 4 4 5 4 3 4 5 4 3 3 5 5 3 5 4 4 4 3 4 4 4 4 4 4 5\n",
            " 5 4 5 5 5 4 4 4 5 5 4 5 4 4 4 4]\n",
            "in a loop of item importance updation\n",
            "Inside Attention Modeling\n",
            "User Profile Values [5, 3, 3, 4, 5, 3, 5, 5, 4, 4, 5, 4, 4, 4, 5, 4, 3, 4, 5, 4, 3, 3, 5, 5, 3, 5, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 5, 5, 4, 5, 5, 5, 4, 4, 4, 5, 5, 4, 5, 4, 4, 4, 4]\n",
            "User Profile Tensor Tensor(\"ExpandDims_12:0\", shape=(1, 53), dtype=float32)\n",
            "(1, 53)\n",
            "Item EMb Tensor(\"transpose_26:0\", shape=(16, 53), dtype=float32)\n",
            "(16, 53)\n",
            "attn: Tensor(\"MatMul_22:0\", shape=(1, 16), dtype=float32)\n",
            "soft att Tensor(\"Softmax_13:0\", shape=(1, 16), dtype=float32)\n",
            "w att: Tensor(\"mul_10/mul:0\", shape=(3706,), dtype=float32)\n",
            "Attention Scores from a func\n",
            "Tensor(\"mul_10/mul:0\", shape=(3706,), dtype=float32)\n",
            "<dtype: 'float32'>\n",
            "<tf.Variable 'Variable_6:0' shape=(3706,) dtype=float32>\n",
            "Grad\n",
            "None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-f48baae5862f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmulti_round_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_recommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-125-2889e1294c6f>\u001b[0m in \u001b[0;36mmulti_round_recommendation\u001b[0;34m(user_id, num_recommendations, num_rounds)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Update item importance weights based on feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_rating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_importance_gradient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_importance_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mitem_importance_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_importance_gradient\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare user profiles and item importance weights\n",
        "user_profiles = {}\n",
        "item_importance_weights = tf.Variable(tf.ones(len(ratings['item_id'].unique())))\n",
        "\n",
        "for user_id, item_id, rating in ratings.values:\n",
        "    if user_id not in user_profiles:\n",
        "        user_profiles[user_id] = {}\n",
        "    user_profiles[user_id][item_id] = rating\n",
        "\n",
        "# Define attention modeling with feedback-based neural network\n",
        "def attention_model(user_profile_tensor, item_ids, item_importance_weights):\n",
        "    # Embed item IDs\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(input_dim=len(ratings['item_id'].unique()), output_dim=16)\n",
        "    item_embeddings = item_embedding_layer(item_ids)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    attention_scores = tf.matmul(user_profile_tensor, item_embeddings.T)\n",
        "    attention_scores = tf.nn.softmax(attention_scores)\n",
        "\n",
        "    # Apply item importance weights\n",
        "    weighted_attention_scores = attention_scores * item_importance_weights\n",
        "\n",
        "    return weighted_attention_scores\n",
        "\n",
        "# Define multi-round recommendation function\n",
        "def multi_round_recommendation(user_id, num_recommendations, num_rounds):\n",
        "    recommendations = []\n",
        "\n",
        "    is_finished = False\n",
        "    for _ in range(num_rounds):\n",
        "        # Get user profile for current round\n",
        "        current_user_profile = user_profiles[user_id]\n",
        "\n",
        "        # Convert user profile to a tensor\n",
        "        user_profile_values = list(current_user_profile.values())\n",
        "        user_profile_tensor = tf.convert_to_tensor(user_profile_values)\n",
        "\n",
        "        # Recommend items based on attention model\n",
        "        item_ids = np.array(list(current_user_profile.keys()))\n",
        "        item_ratings = np.array(list(current_user_profile.values()))\n",
        "\n",
        "        # Update item importance weights using neural network\n",
        "        with tf.GradientTape() as tape:\n",
        "            attention_scores = attention_model(user_profile_tensor, item_ids, item_importance_weights)\n",
        "            item_importance_gradients = tape.gradient(attention_scores, item_importance_weights)\n",
        "\n",
        "        # Update item importance weights based on feedback\n",
        "        for item_id, item_rating, item_importance_gradient in zip(item_ids, item_ratings, item_importance_gradients):\n",
        "            item_importance_weights.assign_sub(item_importance_gradient * item_rating)\n",
        "\n",
        "        # Recommend top n items\n",
        "        recommended_item_ids = item_ids[np.argsort(attention_scores)[-num_recommendations:]]\n",
        "\n",
        "        # Print recommended items\n",
        "        print(\"Recommended items:\")\n",
        "        for item_id in recommended_item_ids:\n",
        "            print(item_id)\n",
        "\n",
        "        # Get user feedback\n",
        "        selected_item_id = input(\"Select an item (or type 'end' to finish): \")\n",
        "\n",
        "        if selected_item_id == 'end':\n",
        "            is_finished = True\n",
        "            break\n",
        "\n",
        "        # Update user profile with new feedback\n",
        "        current_user_profile[selected_item_id] = 1\n",
        "\n",
        "        # Add recommended items to the list\n",
        "        recommendations.extend(recommended_item_ids)\n",
        "\n",
        "    if not is_finished:\n",
        "        print(\"Recommendations:\")\n",
        "        for item_id in recommendations:\n",
        "            print(item_id)\n",
        "\n",
        "# Example usage\n",
        "user_id = 1\n",
        "num_recommendations = 10\n",
        "num_rounds = 3\n",
        "\n",
        "multi_round_recommendation(user_id, num_recommendations, num_rounds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "jaq6UfXAEf8T",
        "outputId": "ab6652f9-37f3-43db-a9e7-4fbf2153889a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5f97cf20d46a>\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmulti_round_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_recommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-5f97cf20d46a>\u001b[0m in \u001b[0;36mmulti_round_recommendation\u001b[0;34m(user_id, num_recommendations, num_rounds)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Update item importance weights using neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_profile_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_importance_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mitem_importance_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_importance_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5f97cf20d46a>\u001b[0m in \u001b[0;36mattention_model\u001b[0;34m(user_profile_tensor, item_ids, item_importance_weights)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Calculate attention scores using neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_profile_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \"tolist\", \"data\"}:\n\u001b[1;32m    255\u001b[0m       \u001b[0;31m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       raise AttributeError(\n\u001b[0m\u001b[1;32m    257\u001b[0m           f\"{type(self).__name__} object has no attribute '{name}'. \" + \"\"\"\n\u001b[1;32m    258\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlooking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrelated\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: EagerTensor object has no attribute 'T'. \n        If you are looking for numpy-related methods, please run the following:\n        tf.experimental.numpy.experimental_enable_numpy_behavior()\n      "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Find the maximum user and movie IDs\n",
        "max_user_id = ratings['user_id'].max()\n",
        "max_movie_id = ratings['item_id'].max()\n",
        "\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = np.zeros((max_user_id, max_movie_id))\n",
        "for user_id, item_id, rating in ratings.values:\n",
        "    user_item_matrix[user_id - 1, item_id - 1] = rating\n",
        "\n",
        "# Define item importance weights\n",
        "item_importance_weights = tf.Variable(tf.ones(len(ratings['item_id'].unique())))\n",
        "\n",
        "# Define attention modeling with feedback-based neural network\n",
        "def attention_model(user_item_matrix, item_ids, item_importance_weights):\n",
        "    # Embed item IDs\n",
        "    item_embedding_layer = tf.keras.layers.Embedding(input_dim=len(ratings['item_id'].unique()), output_dim=16)\n",
        "    item_embeddings = item_embedding_layer(item_ids)\n",
        "\n",
        "    # Transpose item embeddings twice to match user item matrix shape\n",
        "    transposed_item_embeddings = tf.transpose(item_embeddings)\n",
        "    transposed_item_embeddings = tf.transpose(transposed_item_embeddings)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    user_item_embeddings = tf.matmul(user_item_matrix[np.newaxis, :], transposed_item_embeddings)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    # user_item_embeddings = tf.matmul(user_item_matrix[np.newaxis, :], item_embeddings)\n",
        "    attention_scores = tf.nn.softmax(tf.squeeze(user_item_embeddings, axis=0))\n",
        "\n",
        "    # Apply item importance weights\n",
        "    weighted_attention_scores = attention_scores * item_importance_weights\n",
        "\n",
        "    return weighted_attention_scores\n",
        "\n",
        "# Define multi-round recommendation function\n",
        "def multi_round_recommendation(user_id, num_recommendations, num_rounds):\n",
        "    recommendations = []\n",
        "\n",
        "    is_finished = False\n",
        "    for _ in range(num_rounds):\n",
        "        # Recommend items based on attention model\n",
        "        item_ids = np.array(range(len(ratings['item_id'].unique())))\n",
        "\n",
        "        # Update item importance weights using neural network\n",
        "        with tf.GradientTape() as tape:\n",
        "            attention_scores = attention_model(user_item_matrix[user_id - 1, :], item_ids, item_importance_weights)\n",
        "            item_importance_gradients = tape.gradient(attention_scores, item_importance_weights)\n",
        "\n",
        "        # Update item importance weights based on feedback\n",
        "        item_importance_weights.assign_sub(item_importance_gradients * user_item_matrix[user_id - 1, :])\n",
        "\n",
        "        # Recommend top n items\n",
        "        recommended_item_ids = item_ids[np.argsort(attention_scores)[-num_recommendations:]]\n",
        "\n",
        "        # Print recommended items\n",
        "        print(\"Recommended items:\")\n",
        "        for item_id in recommended_item_ids:\n",
        "            print(item_id)\n",
        "\n",
        "        # Get user feedback\n",
        "        selected_item_id = input(\"Select an item (or type 'end' to finish): \")\n",
        "\n",
        "        if selected_item_id == 'end':\n",
        "            is_finished = True\n",
        "            break\n",
        "\n",
        "        # Update user profile with new feedback\n",
        "        user_item_matrix[user_id - 1, selected_item_id - 1] = 1\n",
        "\n",
        "        # Add recommended items to the list\n",
        "        recommendations.extend(recommended_item_ids)\n",
        "\n",
        "    if not is_finished:\n",
        "        print(\"Recommendations:\")\n",
        "        for item_id in recommendations:\n",
        "            print(item_id)\n",
        "\n",
        "# Example usage\n",
        "user_id = 1\n",
        "num_recommendations = 10\n",
        "num_rounds = 3\n",
        "\n",
        "multi_round_recommendation(user_id, num_recommendations, num_rounds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "4DVdBF9pLfEm",
        "outputId": "29879265-6080-4a9f-bdd1-62bcd6db4665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-31408b182921>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mmulti_round_recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_recommendations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-31408b182921>\u001b[0m in \u001b[0;36mmulti_round_recommendation\u001b[0;34m(user_id, num_recommendations, num_rounds)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Update item importance weights using neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_item_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_importance_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mitem_importance_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_importance_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-31408b182921>\u001b[0m in \u001b[0;36mattention_model\u001b[0;34m(user_item_matrix, item_ids, item_importance_weights)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Calculate attention scores using neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0muser_item_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_item_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransposed_item_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Calculate attention scores using neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = np.zeros((len(ratings['user_id'].unique()), len(ratings['item_id'].unique())))\n",
        "for user_id, item_id, rating in ratings.values:\n",
        "    user_item_matrix[user_id - 1, item_id - 1] = rating\n",
        "\n",
        "# Define item importance weights\n",
        "item_importance_weights = tf.Variable(tf.ones(len(ratings['item_id'].unique())))\n",
        "\n",
        "# Define attention modeling with feedback-based neural network\n",
        "def attention_model(user_item_matrix, item_ids, item_importance_weights):\n",
        "    # Create item embedding matrix\n",
        "    item_embedding_matrix = tf.Variable(tf.random.normal([len(ratings['item_id'].unique()), 16]))\n",
        "\n",
        "    # Calculate item embeddings for selected items\n",
        "    item_embeddings_selected = tf.cast(item_embedding_matrix[item_ids], tf.float64)\n",
        "\n",
        "    # Calculate user-item similarity matrix\n",
        "    user_item_embeddings = tf.matmul(user_item_matrix[np.newaxis, :], item_embeddings_selected)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    attention_scores = tf.nn.softmax(tf.squeeze(user_item_embeddings, axis=0))\n",
        "\n",
        "    # Apply item importance weights\n",
        "    weighted_attention_scores = attention_scores * item_importance_weights\n",
        "\n",
        "    return weighted_attention_scores\n",
        "\n",
        "# Define multi-round recommendation function\n",
        "def multi_round_recommendation(user_id, num_recommendations, num_rounds):\n",
        "    recommendations = []\n",
        "\n",
        "    is_finished = False\n",
        "    for _ in range(num_rounds):\n",
        "        # Recommend items based on attention model\n",
        "        item_ids = np.array(range(len(ratings['item_id'].unique())))\n",
        "\n",
        "        # Update item importance weights using neural network\n",
        "        with tf.GradientTape() as tape:\n",
        "            attention_scores = attention_model(user_item_matrix[user_id - 1, :], item_ids, item_importance_weights)\n",
        "            item_importance_gradients = tape.gradient(attention_scores, item_importance_weights)\n",
        "\n",
        "        # Update item importance weights based on feedback\n",
        "        item_importance_weights.assign_sub(item_importance_gradients * user_item_matrix[user_id - 1, :])\n",
        "\n",
        "        # Recommend top n items\n",
        "        recommended_item_ids = item_ids[np.argsort(attention_scores)[-num_recommendations:]]\n",
        "\n",
        "        # Print recommended items\n",
        "        print(\"Recommended items:\")\n",
        "        for item_id in recommended_item_ids:\n",
        "            print(item_id)\n",
        "\n",
        "        # Get user feedback\n",
        "        selected_item_id = input(\"Select an item (or type 'end' to finish): \")\n",
        "\n",
        "        if selected_item_id == 'end':\n",
        "            is_finished = True\n",
        "            break\n",
        "\n",
        "        # Update user profile with new feedback\n",
        "        user_item_matrix[user_id - 1, selected_item_id - 1] = 1\n",
        "\n",
        "        # Add recommended items to the list\n",
        "        recommendations.extend(recommended_item_ids)\n",
        "\n",
        "    if not is_finished:\n",
        "        print(\"Recommendations:\")\n",
        "        for item_id in recommendations:\n",
        "            print(item_id)\n",
        "\n",
        "# Example usage\n",
        "user_id = 1\n",
        "num_recommendations = 10\n",
        "num_rounds = 3\n",
        "\n",
        "multi_round_recommendation(user_id, num_recommendations, num_rounds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "ZdmbvPh3RQRz",
        "outputId": "08d5a4fb-0beb-43dc-8bea-b07fd669c3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-36ecb047b3ba>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muser_item_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define item importance weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3734 is out of bounds for axis 1 with size 3706"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Validate item IDs and filter out invalid ratings\n",
        "valid_ratings = ratings[ratings['item_id'] <= ratings['item_id'].max()]\n",
        "valid_ratings = valid_ratings[valid_ratings['item_id'] >= ratings['item_id'].min()]\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = np.zeros((len(valid_ratings['user_id'].unique()), len(valid_ratings['item_id'].unique())))\n",
        "for user_id, item_id, rating in valid_ratings.values:\n",
        "    user_item_matrix[user_id - 1, item_id - 1] = rating\n",
        "\n",
        "# Define item importance weights\n",
        "item_importance_weights = tf.Variable(tf.ones(len(valid_ratings['item_id'].unique())))\n",
        "\n",
        "# Define attention modeling with feedback-based neural network\n",
        "def attention_model(user_item_matrix, item_ids, item_importance_weights):\n",
        "    # Create item embedding matrix\n",
        "    item_embedding_matrix = tf.Variable(tf.random.normal([len(valid_ratings['item_id'].unique()), 16]))\n",
        "\n",
        "    # Calculate item embeddings for selected items\n",
        "    item_embeddings_selected = tf.cast(item_embedding_matrix[item_ids], tf.float64)\n",
        "\n",
        "    # Calculate user-item similarity matrix\n",
        "    user_item_embeddings = tf.matmul(user_item_matrix[np.newaxis, :], item_embeddings_selected)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    attention_scores = tf.nn.softmax(tf.squeeze(user_item_embeddings, axis=0))\n",
        "\n",
        "    # Apply item importance weights\n",
        "    weighted_attention_scores = attention_scores * item_importance_weights\n",
        "\n",
        "    return weighted_attention_scores\n",
        "\n",
        "# Define multi-round recommendation function\n",
        "def multi_round_recommendation(user_id, num_recommendations, num_rounds):\n",
        "    recommendations = []\n",
        "\n",
        "    is_finished = False\n",
        "    for _ in range(num_rounds):\n",
        "        # Recommend items based on attention model\n",
        "        item_ids = np.array(range(len(valid_ratings['item_id'].unique())))\n",
        "\n",
        "        # Update item importance weights using neural network\n",
        "        with tf.GradientTape() as tape:\n",
        "            attention_scores = attention_model(user_item_matrix[user_id - 1, :], item_ids, item_importance_weights)\n",
        "            item_importance_gradients = tape.gradient(attention_scores, item_importance_weights)\n",
        "\n",
        "        # Update item importance weights based on feedback\n",
        "        item_importance_weights.assign_sub(item_importance_gradients * user_item_matrix[user_id - 1, :])\n",
        "\n",
        "        # Recommend top n items\n",
        "        recommended_item_ids = item_ids[np.argsort(attention_scores)[-num_recommendations:]]\n",
        "\n",
        "        # Print recommended items\n",
        "        print(\"Recommended items:\")\n",
        "        for item_id in recommended_item_ids:\n",
        "            print(item_id)\n",
        "\n",
        "        # Get user feedback\n",
        "        selected_item_id = input(\"Select an item (or type 'end' to finish): \")\n",
        "\n",
        "        if selected_item_id == 'end':\n",
        "            is_finished = True\n",
        "            break\n",
        "\n",
        "        # Update user profile with new feedback\n",
        "        user_item_matrix[user_id - 1, selected_item_id - 1] = 1\n",
        "\n",
        "        # Add recommended items to the list\n",
        "        recommendations.extend(recommended_item_ids)\n",
        "\n",
        "    if not is_finished:\n",
        "        print(\"Recommendations:\")\n",
        "        for item_id in recommendations:\n",
        "            print(item_id)\n",
        "\n",
        "# Example usage\n",
        "user_id = 1\n",
        "num_recommendations = 10\n",
        "num_rounds = 3\n",
        "\n",
        "multi_round_recommendation(user_id, num_recommendations, num_rounds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "VMYRb88RVmAs",
        "outputId": "c25a2c5e-564e-491f-95a5-56e8b5c1f8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-4b91ce065e86>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0muser_item_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_ratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0muser_item_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define item importance weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3734 is out of bounds for axis 1 with size 3706"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load Movielens 100k dataset\n",
        "data_path = 'ml-100k/'\n",
        "ratings = pd.read_csv(data_path + 'u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "ratings = ratings.drop('timestamp', axis=1)\n",
        "\n",
        "# Create a user-item matrix\n",
        "user_item_matrix = np.zeros((len(ratings['user_id'].unique()), len(ratings['item_id'].unique())))\n",
        "for user_id, item_id, rating in ratings.values:\n",
        "    user_item_matrix[user_id - 1, item_id - 1] = rating\n",
        "\n",
        "# Define item importance weights\n",
        "item_importance_weights = tf.Variable(tf.ones(len(ratings['item_id'].unique()), dtype=tf.float32))\n",
        "\n",
        "# Define attention modeling with feedback-based neural network\n",
        "def attention_model(user_item_matrix, item_ids, item_importance_weights):\n",
        "    # Create item embedding matrix\n",
        "    item_embedding_matrix = tf.Variable(tf.random.normal([len(ratings['item_id'].unique()), 16]))\n",
        "\n",
        "    # Calculate item embeddings for selected items\n",
        "    item_embeddings_selected = tf.cast(item_embedding_matrix[item_ids], tf.float32)\n",
        "\n",
        "    # Calculate user-item similarity matrix\n",
        "    user_item_embeddings = tf.matmul(user_item_matrix[np.newaxis, :], item_embeddings_selected)\n",
        "\n",
        "    # Calculate attention scores using neural network\n",
        "    attention_scores = tf.nn.softmax(tf.squeeze(user_item_embeddings, axis=0))\n",
        "\n",
        "    # Apply item importance weights\n",
        "    weighted_attention_scores = attention_scores * item_importance_weights\n",
        "\n",
        "    return weighted_attention_scores\n",
        "\n",
        "# Define multi-round recommendation function\n",
        "def multi_round_recommendation(user_id, num_recommendations, num_rounds):\n",
        "    recommendations = []\n",
        "\n",
        "    is_finished = False\n",
        "    for _ in range(num_rounds):\n",
        "        # Recommend items based on attention model\n",
        "        item_ids = np.array(range(len(ratings['item_id'].unique())))\n",
        "\n",
        "        # Calculate attention scores and item importance gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "            attention_scores = attention_model(user_item_matrix, item_ids, item_importance_weights)\n",
        "            item_importance_gradients = tape.gradient(attention_scores, item_importance_weights)\n",
        "\n",
        "        # Update item importance weights based on feedback\n",
        "        if item_importance_gradients is not None:\n",
        "            for item_id, item_rating, item_importance_gradient in zip(item_ids, item_ratings, item_importance_gradients):\n",
        "                item_importance_weights.assign_sub(item_importance_gradient * item_rating)\n"
      ],
      "metadata": {
        "id": "qIT479NUWCJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define multi-round recommendation function\n",
        "def multi_round_recommendation(user_id, num_recommendations, num_rounds):\n",
        "    print(\"inside multround\")\n",
        "    recommendations = []\n",
        "\n",
        "    is_finished = False\n",
        "    for _ in range(num_rounds):\n",
        "        # Get user profile for current round\n",
        "        current_user_profile = user_profiles[user_id]\n",
        "        print(user_profiles[user_id])\n",
        "        print(current_user_profile)\n",
        "\n",
        "        # Recommend items based on attention model\n",
        "        item_ids = np.array(list(current_user_profile.keys()))\n",
        "        item_ratings = np.array(list(current_user_profile.values()))\n",
        "\n",
        "        print(\"itemID\",item_ids)\n",
        "        print(\"itemRatings\",item_ratings)\n",
        "\n",
        "\n",
        "        # # Update item importance weights using neural network\n",
        "        # with tf.GradientTape() as tape:\n",
        "        #     print(\"in a loop of item importance updation\")\n",
        "        #     attention_scores = attention_model(current_user_profile, item_ids, item_importance_weights)\n",
        "        #     print(\"Attention Scores from a func\")\n",
        "        #     print(attention_scores)\n",
        "        #     print(attention_scores.dtype)\n",
        "        #     print(item_importance_weights)\n",
        "        #     item_importance_gradients = tape.gradient(attention_scores, item_importance_weights)\n",
        "        #     print(\"Grad\")\n",
        "        #     print(item_importance_gradients)\n",
        "\n",
        "                # Calculate the attention scores using the item importance weights\n",
        "        # item_importance_weights = np.zeros(len(item_profiles[user_id]))\n",
        "        # attention_scores = attention_model(current_user_profile, item_ids, item_importance_weights)\n",
        "        learning_rate= 0.01\n",
        "        epsilon= 0.001\n",
        "        # Calculate the approximate gradient\n",
        "        item_importance_gradients = []\n",
        "        for i in range(len(ratings['item_id'])):\n",
        "          item_importance_weights_perturbed = item_importance_weights.copy()\n",
        "          item_importance_weights_perturbed[i] += epsilon\n",
        "          attention_scores_perturbed = attention_model(current_user_profile, item_ids, item_importance_weights_perturbed)\n",
        "          item_importance_gradients.append((attention_scores_perturbed[i] - attention_scores_perturbed [i]) / epsilon)\n",
        "\n",
        "        # Update the item importance weights\n",
        "        item_importance_weights -= learning_rate * item_importance_gradients\n",
        "        # Update item importance weights based on feedback\n",
        "        for item_id, item_rating, item_importance_gradient in zip(item_ids, item_ratings, item_importance_gradients):\n",
        "            item_importance_weights.assign_sub(item_importance_gradient * item_rating)\n",
        "\n",
        "        # Recommend top n items\n",
        "        recommended_item_ids = item_ids[np.argsort(attention_scores_perturbed)[-num_recommendations:]]\n",
        "\n",
        "        print(\"Recommend: \",recommended_item_ids)\n",
        "\n",
        "        # Print recommended items\n",
        "        print(\"Recommended items:\")\n",
        "        for item_id in recommended_item_ids:\n",
        "            print(item_id)\n",
        "\n",
        "        # Get user feedback\n",
        "        selected_item_id = input(\"Select an item (or type 'end' to finish): \")\n",
        "\n",
        "        if selected_item_id == 'end':\n",
        "            is_finished = True\n",
        "            break\n",
        "\n",
        "        # Update user profile with new feedback\n",
        "        current_user_profile[selected_item_id] = 1\n",
        "\n",
        "        # Add recommended items to the list\n",
        "        recommendations.extend(recommended_item_ids)\n",
        "\n",
        "    if not is_finished:\n",
        "        print(\"Recommendations:\")\n",
        "        for item_id in recommendations:\n",
        "            print(item_id)\n"
      ],
      "metadata": {
        "id": "tU3Y9Xv-TiWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.decomposition import NMF\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import ndcg_score\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalAveragePooling1D,  MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "WFGPOGDl9UMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## extracting data\n",
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "ZipFile(\"movielens.zip\", \"r\").extractall()"
      ],
      "metadata": {
        "id": "fnLtzhDN9UMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\n",
        "    \"ml-1m/ratings.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"userId\", \"movieId\", \"rating\", \"unix_timestamp\"],\n",
        ")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "f7368ae6-c882-4139-e122-f1948fb101d8",
        "id": "exJ6PWdv9UMW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7c58046d1af1>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  data = pd.read_csv(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  unix_timestamp\n",
              "0       1     1193       5       978300760\n",
              "1       1      661       3       978302109\n",
              "2       1      914       3       978301968\n",
              "3       1     3408       4       978300275\n",
              "4       1     2355       5       978824291"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-480241ff-2dfd-4c19-92b8-e494b07eff08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>unix_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-480241ff-2dfd-4c19-92b8-e494b07eff08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-480241ff-2dfd-4c19-92b8-e494b07eff08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-480241ff-2dfd-4c19-92b8-e494b07eff08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-90f9e3b7-1b1a-4327-9c72-4200ad976e4d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90f9e3b7-1b1a-4327-9c72-4200ad976e4d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-90f9e3b7-1b1a-4327-9c72-4200ad976e4d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "users = data['userId']\n",
        "movies = data['movieId']\n",
        "ratings = data['rating']\n",
        "\n",
        "# Encode user and movie IDs\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()\n",
        "users = user_encoder.fit_transform(users)\n",
        "movies = movie_encoder.fit_transform(movies)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "users_train, users_test, movies_train, movies_test, ratings_train, ratings_test = train_test_split(\n",
        "    users, movies, ratings, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 32\n",
        "num_heads = 4\n",
        "num_blocks = 2\n",
        "\n",
        "# Define the model\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "\n",
        "user_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "movie_embedding = Embedding(input_dim=len(movie_encoder.classes_), output_dim=embedding_dim)(movie_input)\n",
        "\n",
        "# user_movie_attention = Attention(use_scale=True, num_heads=num_heads)([user_embedding, movie_embedding])\n",
        "\n",
        "# user_movie_representation = GlobalAveragePooling1D()(user_movie_attention)\n",
        "\n",
        "user_movie_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)([user_embedding, movie_embedding])\n",
        "user_movie_representation = GlobalAveragePooling1D()(user_movie_attention)\n",
        "\n",
        "output = Dense(1, activation='linear')(user_movie_representation)\n",
        "\n",
        "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Set parameters for multi-round recommendation\n",
        "num_rounds = 5  # Number of recommendation rounds\n",
        "num_recommendations = 10  # Number of recommendations to provide in each round\n",
        "\n",
        "# Simulate multi-round recommendation\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "    print(f\"\\nRound {round_num}:\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit([users_train, movies_train], ratings_train, epochs=1, batch_size=64, validation_split=0.1)\n",
        "\n",
        "    # Generate top-N recommendations for each user\n",
        "    all_user_ids = np.unique(users_test)\n",
        "    all_movie_ids = np.unique(movies_test)\n",
        "    all_predictions = model.predict([all_user_ids, all_movie_ids])\n",
        "\n",
        "    # Provide top-N recommendations to each user\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    ndcg_scores = []\n",
        "\n",
        "    for user_id in all_user_ids:\n",
        "        top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "        # Simulate user feedback (for demonstration purposes, you can replace this with actual user feedback)\n",
        "        user_feedback = np.random.choice(top_n_recommendations, size=int(num_recommendations / 2), replace=False)\n",
        "        user_ratings = np.random.choice([4, 5], size=int(num_recommendations / 2))  # Simulated positive feedback\n",
        "\n",
        "        # Update the model with user feedback\n",
        "        user_indices = np.where(users_test == user_id)[0]\n",
        "        movie_indices = np.where(np.isin(movies_test[user_indices], user_feedback))[0]\n",
        "        model.fit([users_test[user_indices[movie_indices]], movies_test[user_indices[movie_indices]]],\n",
        "                  ratings_test[user_indices[movie_indices]], epochs=1, batch_size=64)\n",
        "\n",
        "        # Evaluate the model after feedback\n",
        "        true_movies = movies_test[users_test == user_id]\n",
        "        true_ratings = ratings_test[users_test == user_id]\n",
        "\n",
        "        # Get top-N recommendations for the user\n",
        "        top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "        # Precision@k\n",
        "        precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "        precision_scores.append(precision)\n",
        "\n",
        "        # Recall@k\n",
        "        recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "        # NDCG\n",
        "        ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "        ndcg_scores.append(ndcg)\n",
        "\n",
        "    # Calculate and print average scores after each round\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "    avg_ndcg = np.mean(ndcg_scores)\n",
        "\n",
        "    print(f'Precision@{num_recommendations}: {avg_precision}')\n",
        "    print(f'Recall@{num_recommendations}: {avg_recall}')\n",
        "    print(f'NDCG@{num_recommendations}: {avg_ndcg}')\n",
        "\n",
        "# Evaluate the final model\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "ndcg_scores = []\n",
        "\n",
        "for user_id in tqdm(all_user_ids):\n",
        "    true_movies = movies_test[users_test == user_id]\n",
        "    true_ratings = ratings_test[users_test == user_id]\n",
        "\n",
        "    # Get top-N recommendations for the user\n",
        "    top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "    # Precision@k\n",
        "    precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "    precision_scores.append(precision)\n",
        "\n",
        "    # Recall@k\n",
        "    recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "    # NDCG\n",
        "    ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "    ndcg_scores.append(ndcg)\n",
        "\n",
        "# Calculate and print average scores for the final model\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_ndcg = np.mean(ndcg_scores)\n",
        "\n",
        "print(f'Final Model Evaluation:')\n",
        "print(f'Precision@{num_recommendations}: {avg_precision}')\n",
        "print(f'Recall@{num_recommendations}: {avg_recall}')\n",
        "print(f'NDCG@{num_recommendations}: {avg_ndcg}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Cp4vNq-X9K5q",
        "outputId": "0f4c0011-f475-4df1-bdb3-b709c7c75fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2c2f0c7464ff>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# user_movie_representation = GlobalAveragePooling1D()(user_movie_attention)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0muser_movie_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0muser_movie_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_movie_attention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: MultiHeadAttention.call() missing 1 required positional argument: 'value'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode user and movie IDs\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()\n",
        "users = user_encoder.fit_transform(users)\n",
        "movies = movie_encoder.fit_transform(movies)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "users_train, users_test, movies_train, movies_test, ratings_train, ratings_test = train_test_split(\n",
        "    users, movies, ratings, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 32\n",
        "num_heads = 4\n",
        "num_blocks = 2\n",
        "\n",
        "# Define the model\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "\n",
        "user_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "movie_embedding = Embedding(input_dim=len(movie_encoder.classes_), output_dim=embedding_dim)(movie_input)\n",
        "\n",
        "# Create value tensor with the same shape as query tensor\n",
        "value_embedding = Embedding(input_dim=len(movie_encoder.classes_), output_dim=embedding_dim)(movie_input)\n",
        "\n",
        "# Create value tensor with the same shape as query tensor\n",
        "\n",
        "user_movie_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(user_embedding, movie_embedding, value_embedding)\n",
        "user_movie_representation = GlobalAveragePooling1D()(user_movie_attention)\n",
        "\n",
        "\n",
        "output = Dense(1, activation='linear')(user_movie_representation)\n",
        "\n",
        "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Set parameters for multi-round recommendation\n",
        "num_rounds = 5  # Number of recommendation rounds\n",
        "num_recommendations = 10  # Number of recommendations to provide in each round"
      ],
      "metadata": {
        "id": "lvCTavv79meq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate multi-round recommendation\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "    print(f\"\\nRound {round_num}:\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit([users_train, movies_train], ratings_train, epochs=1, batch_size=64, validation_split=0.1)\n",
        "\n",
        "    # Generate top-N recommendations for each user\n",
        "    all_user_ids = np.unique(users_test)\n",
        "    all_movie_ids = np.unique(movies_test)\n",
        "    all_predictions = model.predict([all_user_ids, all_movie_ids])\n",
        "\n",
        "    # Provide top-N recommendations to each user\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    ndcg_scores = []\n",
        "\n",
        "    for user_id in all_user_ids:\n",
        "        top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "        # Simulate user feedback (for demonstration purposes, you can replace this with actual user feedback)\n",
        "        user_feedback = np.random.choice(top_n_recommendations, size=int(num_recommendations / 2), replace=False)\n",
        "        user_ratings = np.random.choice([4, 5], size=int(num_recommendations / 2))  # Simulated positive feedback\n",
        "\n",
        "        # Update the model with user feedback\n",
        "        user_indices = np.where(users_test == user_id)[0]\n",
        "        movie_indices = np.where(np.isin(movies_test[user_indices], user_feedback))[0]\n",
        "        model.fit([users_test[user_indices[movie_indices]], movies_test[user_indices[movie_indices]]],\n",
        "                  ratings_test[user_indices[movie_indices]], epochs=1, batch_size=64)\n",
        "\n",
        "        # Evaluate the model after feedback\n",
        "        true_movies = movies_test[users_test == user_id]\n",
        "        true_ratings = ratings_test[users_test == user_id]\n",
        "\n",
        "        # Get top-N recommendations for the user\n",
        "        top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "        # Precision@k\n",
        "        precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "        precision_scores.append(precision)\n",
        "\n",
        "        # Recall@k\n",
        "        recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "        # NDCG\n",
        "        ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "        ndcg_scores.append(ndcg)\n",
        "\n",
        "    # Calculate and print average scores after each round\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "    avg_ndcg = np.mean(ndcg_scores)\n",
        "\n",
        "    print(f'Precision@{num_recommendations}: {avg_precision}')\n",
        "    print(f'Recall@{num_recommendations}: {avg_recall}')\n",
        "    print(f'NDCG@{num_recommendations}: {avg_ndcg}')\n",
        "\n",
        "# Evaluate the final model\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "ndcg_scores = []\n",
        "\n",
        "for user_id in tqdm(all_user_ids):\n",
        "    true_movies = movies_test[users_test == user_id]\n",
        "    true_ratings = ratings_test[users_test == user_id]\n",
        "\n",
        "    # Get top-N recommendations for the user\n",
        "    top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "    # Precision@k\n",
        "    precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "    precision_scores.append(precision)\n",
        "\n",
        "    # Recall@k\n",
        "    recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "    # NDCG\n",
        "    ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "    ndcg_scores.append(ndcg)\n",
        "\n",
        "# Calculate and print average scores for the final model\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_ndcg = np.mean(ndcg_scores)\n",
        "\n",
        "print(f'Final Model Evaluation:')\n",
        "print(f'Precision@{num_recommendations}: {avg_precision}')\n",
        "print(f'Recall@{num_recommendations}: {avg_recall}')\n",
        "print(f'NDCG@{num_recommendations}: {avg_ndcg}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "wj-oP_9P-TPc",
        "outputId": "63151a7e-677a-49f7-86f5-fa45a5a396f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1:\n",
            "11253/11253 [==============================] - 62s 6ms/step - loss: 0.9724 - val_loss: 0.9718\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-492177e60121>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mall_user_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mall_movie_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mall_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_user_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_movie_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Provide top-N recommendations to each user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1958\u001b[0m             )\n\u001b[1;32m   1959\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 6038, 3444\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import ndcg_score\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalAveragePooling1D, MultiHeadAttention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load MovieLens dataset\n",
        "# Assuming 'ratings.csv' contains columns: userId, movieId, rating\n",
        "data = data\n",
        "users = data['userId']\n",
        "movies = data['movieId']\n",
        "ratings = data['rating']\n",
        "\n",
        "# Encode user and movie IDs\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()\n",
        "users = user_encoder.fit_transform(users)\n",
        "movies = movie_encoder.fit_transform(movies)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "users_train, users_test, movies_train, movies_test, ratings_train, ratings_test = train_test_split(\n",
        "    users, movies, ratings, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 32\n",
        "num_heads = 4\n",
        "num_blocks = 2\n",
        "\n",
        "# Define the model\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "\n",
        "user_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "movie_embedding = Embedding(input_dim=len(movie_encoder.classes_), output_dim=embedding_dim)(movie_input)\n",
        "\n",
        "# Separate Embedding layer for user profiles\n",
        "user_profile_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "\n",
        "# Use user profile embedding as value tensor\n",
        "user_movie_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(user_embedding, movie_embedding, user_profile_embedding)\n",
        "user_movie_representation = GlobalAveragePooling1D()(user_movie_attention)\n",
        "\n",
        "output = Dense(1, activation='linear')(user_movie_representation)\n",
        "\n",
        "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Set parameters for multi-round recommendation\n",
        "num_rounds = 5  # Number of recommendation rounds\n",
        "num_recommendations = 10  # Number of recommendations to provide in each round\n",
        "\n",
        "# Simulate multi-round recommendation\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "    print(f\"\\nRound {round_num}:\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit([users_train, movies_train], ratings_train, epochs=1, batch_size=64, validation_split=0.1)\n",
        "\n",
        "    # Generate top-N recommendations for each user\n",
        "    all_user_ids = np.unique(users_test)\n",
        "    all_movie_ids = np.unique(movies_test)\n",
        "    # all_predictions = model.predict([all_user_ids, all_movie_ids])\n",
        "\n",
        "    # Create a meshgrid of all user IDs and movie IDs\n",
        "    all_user_ids_mesh, all_movie_ids_mesh = np.meshgrid(all_user_ids, all_movie_ids)\n",
        "\n",
        "    all_predictions = model.predict([all_user_ids_mesh.flatten(), all_movie_ids_mesh.flatten()])\n",
        "\n",
        "    # Provide top-N recommendations to each user\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    ndcg_scores = []\n",
        "\n",
        "    for user_id in all_user_ids:\n",
        "        top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "        # Simulate user feedback (for demonstration purposes, you can replace this with actual user feedback)\n",
        "        user_feedback = np.random.choice(top_n_recommendations, size=int(num_recommendations / 2), replace=False)\n",
        "        user_ratings = np.random.choice([4, 5], size=int(num_recommendations / 2))  # Simulated positive feedback\n",
        "\n",
        "        # Update the model with user feedback\n",
        "        user_indices = np.where(users_test == user_id)[0]\n",
        "        movie_indices = np.where(np.isin(movies_test[user_indices], user_feedback))[0]\n",
        "        model.fit([users_test[user_indices[movie_indices]], movies_test[user_indices[movie_indices]]],\n",
        "                  ratings_test[user_indices[movie_indices]], epochs=1, batch_size=64)\n",
        "\n",
        "        # Evaluate the model after feedback\n",
        "        true_movies = movies_test[users_test == user_id]\n",
        "        true_ratings = ratings_test[users_test == user_id]\n",
        "\n",
        "        # Get top-N recommendations for the user\n",
        "        top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "        # Precision@k\n",
        "        precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "        precision_scores.append(precision)\n",
        "\n",
        "        # Recall@k\n",
        "        recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "        # NDCG\n",
        "        ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "        ndcg_scores.append(ndcg)\n",
        "\n",
        "    # Calculate and print average scores after each round\n",
        "    avg_precision = np.mean(precision_scores)\n",
        "    avg_recall = np.mean(recall_scores)\n",
        "    avg_ndcg = np.mean(ndcg_scores)\n",
        "\n",
        "    print(f'Precision@{num_recommendations}: {avg_precision}')\n",
        "    print(f'Recall@{num_recommendations}: {avg_recall}')\n",
        "    print(f'NDCG@{num_recommendations}: {avg_ndcg}')\n",
        "\n",
        "# Evaluate the final model\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "ndcg_scores = []\n",
        "\n",
        "for user_id in tqdm(all_user_ids):\n",
        "    true_movies = movies_test[users_test == user_id]\n",
        "    true_ratings = ratings_test[users_test == user_id]\n",
        "\n",
        "    # Get top-N recommendations for the user\n",
        "    top_n_recommendations = np.argsort(all_predictions[users_test == user_id])[::-1][:num_recommendations]\n",
        "\n",
        "    # Precision@k\n",
        "    precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "    precision_scores.append(precision)\n",
        "\n",
        "    # Recall@k\n",
        "    recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "    # NDCG\n",
        "    ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "    ndcg_scores.append(ndcg)\n",
        "\n",
        "# Calculate and print average scores for the final model\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_ndcg = np.mean(ndcg_scores)\n",
        "\n",
        "print(f'Final Model Evaluation:')\n",
        "print(f'Precision@{num_recommendations}: {avg_precision}')\n",
        "print(f'Recall@{num_recommendations}: {avg_recall}')\n",
        "print(f'NDCG@{num_recommendations}: {avg_ndcg}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "Yq7i61MZ-r6F",
        "outputId": "13d4b3bc-fff8-4919-ae22-a8fdcabf20a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1:\n",
            "11253/11253 [==============================] - 67s 6ms/step - loss: 1.0228 - val_loss: 0.9756\n",
            "649840/649840 [==============================] - 862s 1ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ee83ba585a73>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_user_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mtop_n_recommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0musers_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_recommendations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Simulate user feedback (for demonstration purposes, you can replace this with actual user feedback)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 20794872 but corresponding boolean dimension is 200042"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MovieLens dataset\n",
        "# Assuming 'ratings.csv' contains columns: userId, movieId, rating\n",
        "data = data\n",
        "users = data['userId']\n",
        "movies = data['movieId']\n",
        "ratings = data['rating']\n",
        "\n",
        "# Encode user and movie IDs\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()\n",
        "users = user_encoder.fit_transform(users)\n",
        "movies = movie_encoder.fit_transform(movies)\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 32\n",
        "num_heads = 4\n",
        "num_blocks = 2\n",
        "\n",
        "# Define the model\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "\n",
        "user_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "movie_embedding = Embedding(input_dim=len(movie_encoder.classes_), output_dim=embedding_dim)(movie_input)\n",
        "\n",
        "# Separate Embedding layer for user profiles\n",
        "user_profile_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "\n",
        "# Use user profile embedding as value tensor\n",
        "user_movie_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(user_embedding, movie_embedding, user_profile_embedding)\n",
        "user_movie_representation = GlobalAveragePooling1D()(user_movie_attention)\n",
        "\n",
        "output = Dense(1, activation='linear')(user_movie_representation)\n",
        "\n",
        "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Set parameters for multi-round recommendation\n",
        "num_rounds = 5  # Number of recommendation rounds\n",
        "num_recommendations = 10  # Number of recommendations to provide in each round\n",
        "\n",
        "# Select a specific user for evaluation\n",
        "specific_user_id = np.random.choice(users, size=1)[0]\n",
        "\n",
        "# Simulate multi-round recommendation and feedback for the specific user\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "    print(f\"\\nRound {round_num}:\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit([users, movies], ratings, epochs=1, batch_size=64)\n",
        "\n",
        "    # Generate top-N recommendations for the specific user\n",
        "    user_indices = np.where(users == specific_user_id)[0]\n",
        "    all_movie_ids = np.unique(movies)\n",
        "    all_movie_ids_mesh = np.tile(all_movie_ids, len(user_indices))\n",
        "\n",
        "    all_predictions = model.predict([np.repeat(specific_user_id, len(all_movie_ids_mesh)), all_movie_ids_mesh])\n",
        "\n",
        "    top_n_recommendations = np.argsort(all_predictions[:, 0])[::-1][:num_recommendations]\n",
        "\n",
        "    # Simulate user feedback (for demonstration purposes, you can replace this with actual user feedback)\n",
        "    user_feedback = np.random.choice(top_n_recommendations, size=int(num_recommendations / 2), replace=False)\n",
        "    user_ratings = np.random.choice([4, 5], size=int(num_recommendations / 2))  # Simulated positive feedback\n",
        "\n",
        "    # Update the model with user feedback\n",
        "    model.fit([np.repeat(specific_user_id, len(user_feedback)), user_feedback], user_ratings, epochs=1, batch_size=64)\n",
        "\n",
        "\n",
        "    # Evaluate the model after feedback\n",
        "    true_movies = movies[users == specific_user_id]\n",
        "    true_ratings = ratings[users == specific_user_id]\n",
        "\n",
        "    # Get top-N recommendations for the user\n",
        "    top_n_recommendations = np.argsort(all_predictions[:, 0])[::-1][:num_recommendations]\n",
        "\n",
        "    # Precision@k\n",
        "    precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "\n",
        "    # Recall@k\n",
        "    recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "\n",
        "    # NDCG\n",
        "    ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f'Precision@{num_recommendations}: {precision}')\n",
        "    print(f'Recall@{num_recommendations}: {recall}')\n",
        "    print(f'NDCG@{num_recommendations}: {ndcg}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Hr9YoZ6AOpz",
        "outputId": "e9b92f45-b75d-41d3-c17a-f9b0272b4993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1:\n",
            "15629/15629 [==============================] - 101s 6ms/step - loss: 1.0133\n",
            "57096/57096 [==============================] - 84s 1ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5df398dd9cd7>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Update the model with user feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecific_user_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_feedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_feedback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Evaluate the model after feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node model_3/embedding_25/embedding_lookup defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-17-5df398dd9cd7>\", line 68, in <cell line: 48>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 589, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py\", line 272, in call\n\nindices[0,0] = 1314622 is not in [0, 3706)\n\t [[{{node model_3/embedding_25/embedding_lookup}}]] [Op:__inference_train_function_5862723]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MovieLens dataset\n",
        "# Assuming 'ratings.csv' contains columns: userId, movieId, rating\n",
        "data = data\n",
        "users = data['userId']\n",
        "movies = data['movieId']\n",
        "ratings = data['rating']\n",
        "\n",
        "# Encode user and movie IDs\n",
        "user_encoder = LabelEncoder()\n",
        "movie_encoder = LabelEncoder()\n",
        "users = user_encoder.fit_transform(users)\n",
        "movies = movie_encoder.fit_transform(movies)\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 32\n",
        "num_heads = 4\n",
        "\n",
        "# Define the model\n",
        "user_input = Input(shape=(1,))\n",
        "movie_input = Input(shape=(1,))\n",
        "\n",
        "user_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "movie_embedding = Embedding(input_dim=len(movie_encoder.classes_), output_dim=embedding_dim)(movie_input)\n",
        "\n",
        "# Separate Embedding layer for user profiles\n",
        "user_profile_embedding = Embedding(input_dim=len(user_encoder.classes_), output_dim=embedding_dim)(user_input)\n",
        "\n",
        "# Use user profile embedding as value tensor\n",
        "user_movie_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(user_embedding, movie_embedding, user_profile_embedding)\n",
        "user_movie_representation = GlobalAveragePooling1D()(user_movie_attention)\n",
        "\n",
        "output = Dense(1, activation='linear')(user_movie_representation)\n",
        "\n",
        "model = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Set parameters for multi-round recommendation\n",
        "num_rounds = 5  # Number of recommendation rounds\n",
        "num_recommendations = 10  # Number of recommendations to provide in each round\n",
        "\n",
        "# Select a specific user for evaluation\n",
        "specific_user_id = np.random.choice(users, size=1)[0]\n",
        "\n",
        "# Simulate multi-round recommendation and feedback for the specific user\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "    print(f\"\\nRound {round_num}:\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit([users, movies], ratings, epochs=1, batch_size=64, shuffle=True)\n",
        "\n",
        "    # Generate top-N recommendations for the specific user\n",
        "    all_movie_ids = np.unique(movies)\n",
        "    all_movie_ids_mesh = np.tile(all_movie_ids, len(users))\n",
        "\n",
        "    all_predictions = model.predict([users, all_movie_ids_mesh])\n",
        "\n",
        "    top_n_recommendations = np.argsort(all_predictions[:, 0])[::-1][:num_recommendations]\n",
        "\n",
        "    # Simulate user feedback (for demonstration purposes, you can replace this with actual user feedback)\n",
        "    user_feedback = np.random.choice(top_n_recommendations, size=int(num_recommendations / 2), replace=False)\n",
        "    user_ratings = np.random.choice([4, 5], size=int(num_recommendations / 2))  # Simulated positive feedback\n",
        "\n",
        "    # Update the model with user feedback\n",
        "    model.fit([np.repeat(specific_user_id, len(user_feedback)), user_feedback], user_ratings, epochs=1, batch_size=64)\n",
        "\n",
        "    # Evaluate the model after feedback\n",
        "    true_movies = movies[users == specific_user_id]\n",
        "    true_ratings = ratings[users == specific_user_id]\n",
        "\n",
        "    # Get top-N recommendations for the user\n",
        "    top_n_recommendations = np.argsort(all_predictions[:, 0])[::-1][:num_recommendations]\n",
        "\n",
        "    # Precision@k\n",
        "    precision = precision_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "\n",
        "    # Recall@k\n",
        "    recall = recall_score(true_movies, np.isin(top_n_recommendations, true_movies), average='binary')\n",
        "\n",
        "    # NDCG\n",
        "    ndcg = ndcg_score([true_movies], [top_n_recommendations], k=num_recommendations)\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f'Precision@{num_recommendations}: {precision}')\n",
        "    print(f'Recall@{num_recommendations}: {recall}')\n",
        "    print(f'NDCG@{num_recommendations}: {ndcg}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiaJ0IGLK5XV",
        "outputId": "00a04428-6d15-44ee-9779-9d6777930733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Round 1:\n",
            "15629/15629 [==============================] - 104s 7ms/step - loss: 1.0122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06wZaRVXPpQ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}