{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vipashaaV321/User-Intent-Modeling/blob/main/LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings :\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Handle table-like data and matrices :\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "# Modelling Helpers :\n",
        "from sklearn.preprocessing import Normalizer , scale\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
        "\n",
        "\n",
        "\n",
        "# Evaluation metrics :\n",
        "\n",
        "# Regression\n",
        "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error\n",
        "\n",
        "# Classification\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "\n",
        "# Deep Learning Libraries\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "# Configure visualisations\n",
        "%matplotlib inline\n",
        "mpl.style.use( 'ggplot' )\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)"
      ],
      "metadata": {
        "id": "37OK1wxQ6kFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv('/content/ratings.csv')\n",
        "movies = pd.read_csv('/content/movies.csv')\n",
        "df_r = ratings.copy()\n",
        "df_m = movies.copy()"
      ],
      "metadata": {
        "id": "M_WtIFKG8Evl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Input, dot, concatenate\n",
        "from keras.models import Model\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "metadata": {
        "id": "07yOnwO98z9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate"
      ],
      "metadata": {
        "id": "FBwXZqHHV0g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = ratings.iloc[:,:2]\n",
        "Y = ratings.iloc[:,2]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 66)"
      ],
      "metadata": {
        "id": "5JW52rL4-P4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aWt2rR3cyrJ",
        "outputId": "ab072bbf-0f94-4fd8-edf5-4e480336729c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         2.5\n",
              "1         3.0\n",
              "2         3.0\n",
              "3         2.0\n",
              "4         4.0\n",
              "         ... \n",
              "99999     2.5\n",
              "100000    4.0\n",
              "100001    4.0\n",
              "100002    2.5\n",
              "100003    3.5\n",
              "Name: rating, Length: 100004, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "I6SNLMxF6mZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate"
      ],
      "metadata": {
        "id": "1U-up7uKyQaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate\n",
        "\n",
        "# Assuming you have training data in the form of user indices and movie indices\n",
        "user_indices = X['userId']  # List of user indices\n",
        "movie_indices =X['movieId'] # List of movie indices\n",
        "labels = Y # List of corresponding ratings\n",
        "\n",
        "# Convert the data to NumPy arrays\n",
        "user_indices = np.array(user_indices)\n",
        "movie_indices = np.array(movie_indices)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_size = int(0.8 * len(user_indices))  # 80% for training, 20% for validation\n",
        "train_user_indices = user_indices[:train_size]\n",
        "train_movie_indices = movie_indices[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "val_user_indices = user_indices[train_size:]\n",
        "val_movie_indices = movie_indices[train_size:]\n",
        "val_labels = labels[train_size:]\n",
        "\n",
        "# Define the input dimensions\n",
        "num_users = np.max(user_indices) + 1  # Number of unique users\n",
        "num_movies = np.max(movie_indices) + 1  # Number of unique movies\n",
        "embedding_dim = 50  # Embedding dimension for both users and movies\n",
        "\n",
        "# User input\n",
        "user_input = keras.Input(shape=(1,))\n",
        "user_embedding = Embedding(num_users, embedding_dim)(user_input)\n",
        "user_embedding = keras.layers.Flatten()(user_embedding)\n",
        "\n",
        "# Movie input\n",
        "movie_input = keras.Input(shape=(1,))\n",
        "movie_embedding = Embedding(num_movies, embedding_dim)(movie_input)\n",
        "movie_embedding = keras.layers.Flatten()(movie_embedding)\n",
        "\n",
        "# Concatenate user and movie embeddings\n",
        "concatenated = Concatenate()([user_embedding, movie_embedding])\n",
        "\n",
        "# Reshape the input to match LSTM's expected input shape\n",
        "reshaped = keras.layers.Reshape((2, embedding_dim))(concatenated)\n",
        "\n",
        "# Apply RNN model\n",
        "rnn_output = LSTM(64)(reshaped)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1, activation='relu')(rnn_output)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=[tf.keras.metrics.Recall()])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    [train_user_indices, train_movie_indices],\n",
        "    train_labels,\n",
        "    validation_data=([val_user_indices, val_movie_indices], val_labels),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "h3Gdgx3zY80k",
        "outputId": "f7a88ae2-ce0c-47b4-9109-ad6a81fcc883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2501/2501 [==============================] - 264s 104ms/step - loss: 0.7911 - recall: 0.9842 - val_loss: 0.8298 - val_recall: 1.0000\n",
            "Epoch 2/10\n",
            "2501/2501 [==============================] - 256s 102ms/step - loss: 0.6733 - recall: 1.0000 - val_loss: 0.7443 - val_recall: 1.0000\n",
            "Epoch 3/10\n",
            "2501/2501 [==============================] - 257s 103ms/step - loss: 0.6534 - recall: 0.9999 - val_loss: 0.7631 - val_recall: 1.0000\n",
            "Epoch 4/10\n",
            "2501/2501 [==============================] - 255s 102ms/step - loss: 0.6350 - recall: 0.9998 - val_loss: 0.7718 - val_recall: 1.0000\n",
            "Epoch 5/10\n",
            "1390/2501 [===============>..............] - ETA: 2:02 - loss: 0.6177 - recall: 0.9998"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-7c26bc71f94e>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtrain_user_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_movie_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifiacation"
      ],
      "metadata": {
        "id": "jtnxTDWX6h91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['movieId']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNKDkvBn74MH",
        "outputId": "fa7f4d66-a72f-4831-c210-b3b26275b493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           31\n",
              "1         1029\n",
              "2         1061\n",
              "3         1129\n",
              "4         1172\n",
              "          ... \n",
              "99999     6268\n",
              "100000    6269\n",
              "100001    6365\n",
              "100002    6385\n",
              "100003    6565\n",
              "Name: movieId, Length: 100004, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you have training data in the form of user indices and movie indices\n",
        "user_indices = X['userId']  # List of user indices\n",
        "movie_indices =X['movieId'] # List of movie indices\n",
        "labels = Y # List of corresponding ratings\n",
        "\n",
        "# Convert the data to NumPy arrays\n",
        "user_indices = np.array(user_indices)\n",
        "movie_indices = np.array(movie_indices)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_size = int(0.8 * len(user_indices))  # 80% for training, 20% for validation\n",
        "train_user_indices = user_indices[:train_size]\n",
        "train_movie_indices = movie_indices[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "val_user_indices = user_indices[train_size:]\n",
        "val_movie_indices = movie_indices[train_size:]\n",
        "val_labels = labels[train_size:]\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "train_labels_onehot = to_categorical(train_labels, num_classes=10)\n",
        "val_labels_onehot = to_categorical(val_labels, num_classes=10)\n",
        "\n",
        "# Define the input dimensions\n",
        "num_users = np.max(user_indices) + 1  # Number of unique users\n",
        "num_movies = np.max(movie_indices) + 1  # Number of unique movies\n",
        "embedding_dim = 50  # Embedding dimension for both users and movies\n",
        "\n",
        "# User input\n",
        "user_input = keras.Input(shape=(1,))\n",
        "user_embedding = Embedding(num_users, embedding_dim)(user_input)\n",
        "user_embedding = keras.layers.Flatten()(user_embedding)\n",
        "\n",
        "# Movie input\n",
        "movie_input = keras.Input(shape=(1,))\n",
        "movie_embedding = Embedding(num_movies, embedding_dim)(movie_input)\n",
        "movie_embedding = keras.layers.Flatten()(movie_embedding)\n",
        "\n",
        "# Concatenate user and movie embeddings\n",
        "concatenated = Concatenate()([user_embedding, movie_embedding])\n",
        "\n",
        "# Reshape the input to match LSTM's expected input shape\n",
        "reshaped = keras.layers.Reshape((2, embedding_dim))(concatenated)\n",
        "\n",
        "# Apply RNN model\n",
        "rnn_output = LSTM(64)(reshaped)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(10, activation='softmax')(rnn_output)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    [train_user_indices, train_movie_indices],\n",
        "    train_labels_onehot,\n",
        "    validation_data=([val_user_indices, val_movie_indices], val_labels_onehot),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate([val_user_indices, val_movie_indices], val_labels_onehot)\n",
        "print(\"Updated model accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6loQIx_ukdBc",
        "outputId": "161e487d-0807-45fd-ddfe-66a6f4a34bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2501/2501 [==============================] - 256s 101ms/step - loss: 1.3316 - accuracy: 0.4349 - val_loss: 1.3671 - val_accuracy: 0.4138\n",
            "Epoch 2/10\n",
            "2501/2501 [==============================] - 253s 101ms/step - loss: 1.1978 - accuracy: 0.4935 - val_loss: 1.3886 - val_accuracy: 0.4036\n",
            "Epoch 3/10\n",
            "2501/2501 [==============================] - 253s 101ms/step - loss: 1.1434 - accuracy: 0.5189 - val_loss: 1.3925 - val_accuracy: 0.3984\n",
            "Epoch 4/10\n",
            "2501/2501 [==============================] - 253s 101ms/step - loss: 1.1022 - accuracy: 0.5343 - val_loss: 1.4042 - val_accuracy: 0.3996\n",
            "Epoch 5/10\n",
            "2501/2501 [==============================] - 254s 102ms/step - loss: 1.0640 - accuracy: 0.5481 - val_loss: 1.4285 - val_accuracy: 0.3935\n",
            "Epoch 6/10\n",
            "2501/2501 [==============================] - 253s 101ms/step - loss: 1.0280 - accuracy: 0.5596 - val_loss: 1.4605 - val_accuracy: 0.3817\n",
            "Epoch 7/10\n",
            "2501/2501 [==============================] - 254s 102ms/step - loss: 0.9961 - accuracy: 0.5736 - val_loss: 1.4895 - val_accuracy: 0.3789\n",
            "Epoch 8/10\n",
            "2501/2501 [==============================] - 256s 103ms/step - loss: 0.9673 - accuracy: 0.5855 - val_loss: 1.5340 - val_accuracy: 0.3666\n",
            "Epoch 9/10\n",
            "2501/2501 [==============================] - 256s 103ms/step - loss: 0.9385 - accuracy: 0.5969 - val_loss: 1.5731 - val_accuracy: 0.3692\n",
            "Epoch 10/10\n",
            "2501/2501 [==============================] - 254s 101ms/step - loss: 0.9114 - accuracy: 0.6097 - val_loss: 1.6075 - val_accuracy: 0.3733\n",
            "626/626 [==============================] - 1s 2ms/step - loss: 1.6075 - accuracy: 0.3733\n",
            "Updated model accuracy: 0.373281329870224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you have training data in the form of user indices and movie indices\n",
        "user_indices = X['userId']  # List of user indices\n",
        "movie_indices =X['movieId'] # List of movie indices\n",
        "labels = Y # List of corresponding ratings\n",
        "\n",
        "# Convert the data to NumPy arrays\n",
        "user_indices = np.array(user_indices)\n",
        "movie_indices = np.array(movie_indices)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_size = int(0.8 * len(user_indices))  # 80% for training, 20% for validation\n",
        "train_user_indices = user_indices[:train_size]\n",
        "train_movie_indices = movie_indices[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "val_user_indices = user_indices[train_size:]\n",
        "val_movie_indices = movie_indices[train_size:]\n",
        "val_labels = labels[train_size:]\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "train_labels_onehot = to_categorical(train_labels, num_classes=10)\n",
        "val_labels_onehot = to_categorical(val_labels, num_classes=10)\n",
        "\n",
        "# Define the input dimensions\n",
        "num_users = np.max(user_indices) + 1  # Number of unique users\n",
        "num_movies = np.max(movie_indices) + 1  # Number of unique movies\n",
        "embedding_dim = 50  # Embedding dimension for both users and movies\n",
        "\n",
        "# User input\n",
        "user_input = keras.Input(shape=(1,))\n",
        "user_embedding = Embedding(num_users, embedding_dim)(user_input)\n",
        "user_embedding = keras.layers.Flatten()(user_embedding)\n",
        "\n",
        "# Movie input\n",
        "movie_input = keras.Input(shape=(1,))\n",
        "movie_embedding = Embedding(num_movies, embedding_dim)(movie_input)\n",
        "movie_embedding = keras.layers.Flatten()(movie_embedding)\n",
        "\n",
        "# Concatenate user and movie embeddings\n",
        "concatenated = Concatenate()([user_embedding, movie_embedding])\n",
        "\n",
        "# Reshape the input to match LSTM's expected input shape\n",
        "reshaped = keras.layers.Reshape((2, embedding_dim))(concatenated)\n",
        "\n",
        "# Apply RNN model\n",
        "rnn_output = LSTM(64)(reshaped)\n",
        "\n",
        "# Output layer\n",
        "output = Dense(10, activation='softmax')(rnn_output)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    [train_user_indices, train_movie_indices],\n",
        "    train_labels_onehot,\n",
        "    validation_data=([val_user_indices, val_movie_indices], val_labels_onehot),\n",
        "    epochs=1,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate([val_user_indices, val_movie_indices], val_labels_onehot)\n",
        "print(\"Updated model accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWRCQhceyTn-",
        "outputId": "c614c8c3-b65f-40aa-97a0-9bd5470cac01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2501/2501 [==============================] - 276s 109ms/step - loss: 1.3285 - accuracy: 0.4355 - val_loss: 1.3824 - val_accuracy: 0.4050\n",
            "626/626 [==============================] - 1s 2ms/step - loss: 1.3824 - accuracy: 0.4050\n",
            "Updated model accuracy: 0.4050297439098358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_user_indices = x_test['userId']  # List of user indices\n",
        "test_movie_indices = x_test['movieId']   # List of movie indices\n",
        "\n",
        "# Convert the test data to NumPy arrays\n",
        "test_user_indices = np.array(test_user_indices)\n",
        "test_movie_indices = np.array(test_movie_indices)\n",
        "\n",
        "# Get the model's predictions\n",
        "predictions = model.predict([test_user_indices, test_movie_indices])\n",
        "\n",
        "# Rank the movies based on predictions\n",
        "movie_indices_ranked = np.argsort(predictions, axis=0)[::-1][:, 0]\n",
        "\n",
        "# Get the top 5 movieIds\n",
        "top_5_movieIds = movie_indices[movie_indices_ranked][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvthXA7nwSww",
        "outputId": "82a84d99-108b-41c0-8e64-779a08499421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "626/626 [==============================] - 2s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_5_movieIds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez5YRjYJwsiW",
        "outputId": "5edcd495-804e-475e-813d-5c00457aecb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1580, 6303,    1, 4002,  613])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['userId']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Dss_BEFJ0g",
        "outputId": "f07ebd91-ab1f-48fa-c6de-867dbdcd7818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           1\n",
              "1           1\n",
              "2           1\n",
              "3           1\n",
              "4           1\n",
              "         ... \n",
              "99999     671\n",
              "100000    671\n",
              "100001    671\n",
              "100002    671\n",
              "100003    671\n",
              "Name: userId, Length: 100004, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have the user ID for which you want to select the data\n",
        "selected_user_id = 671\n",
        "\n",
        "# Filter the dataset to select the data for the selected user\n",
        "selected_user_indices = np.where(user_indices == selected_user_id)[0]\n",
        "selected_user_movie_indices = movie_indices[selected_user_indices]\n",
        "selected_user_labels = labels[selected_user_indices]\n",
        "\n",
        "# Create an array with the same length as selected_user_indices, representing the user index\n",
        "selected_user_indices = np.full_like(selected_user_indices, selected_user_id)\n",
        "\n",
        "# Apply the model using the selected user's data\n",
        "predictions = model.predict([selected_user_indices, selected_user_movie_indices])\n",
        "\n",
        "# Process the predictions as needed\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "SPP1R5GhAMI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b6ff15-8263-45b3-aefb-35d85e63b7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_user_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59m8fymKGlzw",
        "outputId": "4616c99c-4f87-43e8-f784-b961189c2a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5. , 4. , 4.5, 4. , 5. , 4. , 5. , 5. , 3. , 2.5, 4. , 4. , 5. ,\n",
              "       4. , 5. , 4. , 4. , 4. , 4. , 5. , 3.5, 4. , 4. , 5. , 5. , 5. ,\n",
              "       3.5, 5. , 3. , 4. , 3. , 4. , 4. , 4. , 4. , 4. , 4. , 4. , 4. ,\n",
              "       4. , 4. , 3.5, 3. , 4. , 4. , 3.5, 4. , 4. , 3.5, 5. , 4. , 4. ,\n",
              "       4. , 4. , 4. , 3.5, 4.5, 4. , 4. , 3.5, 4. , 5. , 4. , 4. , 4. ,\n",
              "       4.5, 1. , 4. , 5. , 4. , 3. , 3. , 4. , 4. , 4. , 2. , 3. , 4. ,\n",
              "       2. , 3.5, 4. , 3.5, 3.5, 4. , 4. , 4.5, 5. , 3.5, 4. , 5. , 5. ,\n",
              "       4.5, 4.5, 5. , 4. , 2. , 2. , 3. , 4. , 4. , 4.5, 3. , 4. , 4. ,\n",
              "       3.5, 5. , 4. , 4.5, 4. , 2.5, 2.5, 4. , 4. , 2.5, 3.5])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_user_movie_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkfYyJ0zGE2s",
        "outputId": "59341589-1285-426e-de8c-77041b6fd609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,   36,   50,  230,  260,  296,  318,  356,  357,  432,  457,\n",
              "        529,  551,  588,  589,  590,  608,  745,  919, 1035, 1036, 1080,\n",
              "       1090, 1136, 1148, 1196, 1197, 1198, 1206, 1220, 1223, 1225, 1240,\n",
              "       1247, 1259, 1265, 1266, 1291, 1387, 1610, 1641, 1673, 1676, 1704,\n",
              "       1923, 2011, 2028, 2064, 2194, 2291, 2324, 2355, 2359, 2396, 2401,\n",
              "       2502, 2571, 2683, 2762, 2795, 2797, 2804, 2858, 2918, 2959, 2997,\n",
              "       3052, 3060, 3114, 3147, 3160, 3253, 3271, 3386, 3421, 3481, 3671,\n",
              "       3751, 3897, 3996, 4011, 4019, 4022, 4027, 4033, 4034, 4306, 4308,\n",
              "       4880, 4886, 4896, 4963, 4973, 4993, 4995, 5010, 5218, 5299, 5349,\n",
              "       5377, 5445, 5464, 5669, 5816, 5902, 5952, 5989, 5991, 5995, 6212,\n",
              "       6268, 6269, 6365, 6385, 6565])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rank the movies based on predictions\n",
        "movie_indices_ranked = np.argsort(predictions, axis=0)[::-1][:, 0]\n",
        "\n",
        "# Get the top 5 movieIds\n",
        "top_5_movieIds = movie_indices[movie_indices_ranked][:5]\n",
        "\n",
        "top_5_movieIds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeDCSd_xFyOC",
        "outputId": "e79ecbec-8f55-43c1-b0f2-27a614b076b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1343,  253,  595,  866,  736])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict([selected_user_indices, selected_user_movie_indices])  # Predictions from the model\n",
        "top_movie_indices =movie_indices[movie_indices_ranked][:5] # Indices of the top movie IDs\n",
        "\n",
        "# Validate the indices to ensure they are within the bounds of the predictions array\n",
        "valid_movie_indices = [idx for idx in top_movie_indices if idx < len(predictions)]\n",
        "\n",
        "# Get the predicted ratings for the valid top movie indices\n",
        "top_movie_ratings = np.argmax(predictions[valid_movie_indices], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpSIWAHX0jye",
        "outputId": "6880504f-d367-4b45-85cf-e5b3d2985ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "bvGhM0ObHMs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_mapping = {\n",
        "    0: 0.5,  # index 0 corresponds to rating category 1\n",
        "    1: 1,  # index 1 corresponds to rating category 2\n",
        "    2: 1.5,  # index 2 corresponds to rating category 3\n",
        "    3: 2,  # index 3 corresponds to rating category 4\n",
        "    4: 2.5 ,  # index 4 corresponds to rating category 5\n",
        "    5:3 ,\n",
        "    6:3.5,\n",
        "    7:4,\n",
        "    8:4.5,\n",
        "    9:5\n",
        "}"
      ],
      "metadata": {
        "id": "o_Bz5Ezh2MCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_indices = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "P4llXTFs2yCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_indices"
      ],
      "metadata": {
        "id": "XKZf-0CM3fYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_ratings = [rating_mapping[index] for index in highest_indices]"
      ],
      "metadata": {
        "id": "68KmYxOI56yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_ratings"
      ],
      "metadata": {
        "id": "JYopLMsx6Lnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_embeddings"
      ],
      "metadata": {
        "id": "p0yEDzruDf_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot( model,  show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6tAwCTS--bRt",
        "outputId": "20cdcdb8-bbb1-4a5b-dd09-391a35b09e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"650pt\" height=\"737pt\" viewBox=\"0.00 0.00 487.50 553.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(0.75 0.75) rotate(0) translate(4 549)\">\n<title>G</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-549 483.5,-549 483.5,4 -4,4\"/>\n<!-- 140323026354768 -->\n<g id=\"node1\" class=\"node\">\n<title>140323026354768</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"7.5,-498.5 7.5,-544.5 217.5,-544.5 217.5,-498.5 7.5,-498.5\"/>\n<text text-anchor=\"middle\" x=\"46\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"7.5,-521.5 84.5,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"46\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"84.5,-498.5 84.5,-544.5 \"/>\n<text text-anchor=\"middle\" x=\"112\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"84.5,-521.5 139.5,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"112\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"139.5,-498.5 139.5,-544.5 \"/>\n<text text-anchor=\"middle\" x=\"178.5\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 1)]</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"139.5,-521.5 217.5,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"178.5\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 1)]</text>\n</g>\n<!-- 140323026355536 -->\n<g id=\"node3\" class=\"node\">\n<title>140323026355536</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-415.5 0,-461.5 225,-461.5 225,-415.5 0,-415.5\"/>\n<text text-anchor=\"middle\" x=\"40\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">embedding</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"0,-438.5 80,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"40\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"80,-415.5 80,-461.5 \"/>\n<text text-anchor=\"middle\" x=\"107.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"80,-438.5 135,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"107.5\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"135,-415.5 135,-461.5 \"/>\n<text text-anchor=\"middle\" x=\"180\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"135,-438.5 225,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"180\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1, 50)</text>\n</g>\n<!-- 140323026354768&#45;&gt;140323026355536 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140323026354768-&gt;140323026355536</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112.5,-498.37C112.5,-490.15 112.5,-480.66 112.5,-471.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"116,-471.61 112.5,-461.61 109,-471.61 116,-471.61\"/>\n</g>\n<!-- 140322591415392 -->\n<g id=\"node2\" class=\"node\">\n<title>140322591415392</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"256.5,-498.5 256.5,-544.5 466.5,-544.5 466.5,-498.5 256.5,-498.5\"/>\n<text text-anchor=\"middle\" x=\"295\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input_2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"256.5,-521.5 333.5,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"295\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">InputLayer</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"333.5,-498.5 333.5,-544.5 \"/>\n<text text-anchor=\"middle\" x=\"361\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"333.5,-521.5 388.5,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"361\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"388.5,-498.5 388.5,-544.5 \"/>\n<text text-anchor=\"middle\" x=\"427.5\" y=\"-529.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 1)]</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"388.5,-521.5 466.5,-521.5 \"/>\n<text text-anchor=\"middle\" x=\"427.5\" y=\"-506.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 1)]</text>\n</g>\n<!-- 140323028314592 -->\n<g id=\"node4\" class=\"node\">\n<title>140323028314592</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"243.5,-415.5 243.5,-461.5 479.5,-461.5 479.5,-415.5 243.5,-415.5\"/>\n<text text-anchor=\"middle\" x=\"289\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">embedding_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"243.5,-438.5 334.5,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"289\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">Embedding</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"334.5,-415.5 334.5,-461.5 \"/>\n<text text-anchor=\"middle\" x=\"362\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"334.5,-438.5 389.5,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"362\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"389.5,-415.5 389.5,-461.5 \"/>\n<text text-anchor=\"middle\" x=\"434.5\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"389.5,-438.5 479.5,-438.5 \"/>\n<text text-anchor=\"middle\" x=\"434.5\" y=\"-423.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1, 50)</text>\n</g>\n<!-- 140322591415392&#45;&gt;140323028314592 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140322591415392-&gt;140323028314592</title>\n<path fill=\"none\" stroke=\"black\" d=\"M361.5,-498.37C361.5,-490.15 361.5,-480.66 361.5,-471.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"365,-471.61 361.5,-461.61 358,-471.61 365,-471.61\"/>\n</g>\n<!-- 140322591221808 -->\n<g id=\"node5\" class=\"node\">\n<title>140322591221808</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"26,-332.5 26,-378.5 225,-378.5 225,-332.5 26,-332.5\"/>\n<text text-anchor=\"middle\" x=\"53\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">flatten</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"26,-355.5 80,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"53\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">Flatten</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"80,-332.5 80,-378.5 \"/>\n<text text-anchor=\"middle\" x=\"107.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"80,-355.5 135,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"107.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"135,-332.5 135,-378.5 \"/>\n<text text-anchor=\"middle\" x=\"180\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1, 50)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"135,-355.5 225,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"180\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 50)</text>\n</g>\n<!-- 140323026355536&#45;&gt;140322591221808 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140323026355536-&gt;140322591221808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116.05,-415.37C117.37,-407.15 118.89,-397.66 120.33,-388.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"123.82,-389.04 121.95,-378.61 116.91,-387.93 123.82,-389.04\"/>\n</g>\n<!-- 140323028319392 -->\n<g id=\"node6\" class=\"node\">\n<title>140323028319392</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"249.5,-332.5 249.5,-378.5 459.5,-378.5 459.5,-332.5 249.5,-332.5\"/>\n<text text-anchor=\"middle\" x=\"282\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">flatten_1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"249.5,-355.5 314.5,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"282\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">Flatten</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"314.5,-332.5 314.5,-378.5 \"/>\n<text text-anchor=\"middle\" x=\"342\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"314.5,-355.5 369.5,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"342\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"369.5,-332.5 369.5,-378.5 \"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-363.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1, 50)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"369.5,-355.5 459.5,-355.5 \"/>\n<text text-anchor=\"middle\" x=\"414.5\" y=\"-340.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 50)</text>\n</g>\n<!-- 140323028314592&#45;&gt;140323028319392 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140323028314592-&gt;140323028319392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M359.59,-415.37C358.88,-407.15 358.06,-397.66 357.28,-388.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"360.76,-388.27 356.41,-378.61 353.78,-388.87 360.76,-388.27\"/>\n</g>\n<!-- 140323026357504 -->\n<g id=\"node7\" class=\"node\">\n<title>140323026357504</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"91.5,-249.5 91.5,-295.5 381.5,-295.5 381.5,-249.5 91.5,-249.5\"/>\n<text text-anchor=\"middle\" x=\"133\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">concatenate</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"91.5,-272.5 174.5,-272.5 \"/>\n<text text-anchor=\"middle\" x=\"133\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">Concatenate</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"174.5,-249.5 174.5,-295.5 \"/>\n<text text-anchor=\"middle\" x=\"202\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"174.5,-272.5 229.5,-272.5 \"/>\n<text text-anchor=\"middle\" x=\"202\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"229.5,-249.5 229.5,-295.5 \"/>\n<text text-anchor=\"middle\" x=\"305.5\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">[(None, 50), (None, 50)]</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"229.5,-272.5 381.5,-272.5 \"/>\n<text text-anchor=\"middle\" x=\"305.5\" y=\"-257.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100)</text>\n</g>\n<!-- 140322591221808&#45;&gt;140323026357504 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140322591221808-&gt;140323026357504</title>\n<path fill=\"none\" stroke=\"black\" d=\"M155.83,-332.37C168.8,-322.9 184.1,-311.74 197.87,-301.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"200.19,-304.33 206.21,-295.61 196.06,-298.67 200.19,-304.33\"/>\n</g>\n<!-- 140323028319392&#45;&gt;140323026357504 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140323028319392-&gt;140323026357504</title>\n<path fill=\"none\" stroke=\"black\" d=\"M322.26,-332.37C308.34,-322.81 291.9,-311.53 277.16,-301.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"278.93,-298.38 268.71,-295.61 274.97,-304.15 278.93,-298.38\"/>\n</g>\n<!-- 140323028308112 -->\n<g id=\"node8\" class=\"node\">\n<title>140323028308112</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"133,-166.5 133,-212.5 340,-212.5 340,-166.5 133,-166.5\"/>\n<text text-anchor=\"middle\" x=\"164\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">reshape</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"133,-189.5 195,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"164\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">Reshape</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"195,-166.5 195,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"222.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"195,-189.5 250,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"222.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"250,-166.5 250,-212.5 \"/>\n<text text-anchor=\"middle\" x=\"295\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 100)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"250,-189.5 340,-189.5 \"/>\n<text text-anchor=\"middle\" x=\"295\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2, 50)</text>\n</g>\n<!-- 140323026357504&#45;&gt;140323028308112 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140323026357504-&gt;140323028308112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M236.5,-249.37C236.5,-241.15 236.5,-231.66 236.5,-222.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"240,-222.61 236.5,-212.61 233,-222.61 240,-222.61\"/>\n</g>\n<!-- 140323028315408 -->\n<g id=\"node9\" class=\"node\">\n<title>140323028315408</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"137,-83.5 137,-129.5 336,-129.5 336,-83.5 137,-83.5\"/>\n<text text-anchor=\"middle\" x=\"164\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">lstm_7</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"137,-106.5 191,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"164\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">LSTM</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"191,-83.5 191,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"191,-106.5 246,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"246,-83.5 246,-129.5 \"/>\n<text text-anchor=\"middle\" x=\"291\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 2, 50)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"246,-106.5 336,-106.5 \"/>\n<text text-anchor=\"middle\" x=\"291\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n</g>\n<!-- 140323028308112&#45;&gt;140323028315408 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140323028308112-&gt;140323028315408</title>\n<path fill=\"none\" stroke=\"black\" d=\"M236.5,-166.37C236.5,-158.15 236.5,-148.66 236.5,-139.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"240,-139.61 236.5,-129.61 233,-139.61 240,-139.61\"/>\n</g>\n<!-- 140323025107840 -->\n<g id=\"node10\" class=\"node\">\n<title>140323025107840</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"137,-0.5 137,-46.5 336,-46.5 336,-0.5 137,-0.5\"/>\n<text text-anchor=\"middle\" x=\"171\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">dense_30</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"137,-23.5 205,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"171\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"205,-0.5 205,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"232.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">input:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"205,-23.5 260,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"232.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">output:</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260,-0.5 260,-46.5 \"/>\n<text text-anchor=\"middle\" x=\"298\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 64)</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"260,-23.5 336,-23.5 \"/>\n<text text-anchor=\"middle\" x=\"298\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">(None, 1)</text>\n</g>\n<!-- 140323028315408&#45;&gt;140323025107840 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140323028315408-&gt;140323025107840</title>\n<path fill=\"none\" stroke=\"black\" d=\"M236.5,-83.37C236.5,-75.15 236.5,-65.66 236.5,-56.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"240,-56.61 236.5,-46.61 233,-56.61 240,-56.61\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFzX6un5-dMZ",
        "outputId": "68783066-7a5c-47d5-c979-953f64f7115a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_23\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_23 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_24 (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_22 (Embedding)       (None, 1, 50)        33600       ['input_23[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_23 (Embedding)       (None, 1, 50)        8197500     ['input_24[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_22 (Flatten)           (None, 50)           0           ['embedding_22[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_23 (Flatten)           (None, 50)           0           ['embedding_23[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 100)          0           ['flatten_22[0][0]',             \n",
            "                                                                  'flatten_23[0][0]']             \n",
            "                                                                                                  \n",
            " reshape_11 (Reshape)           (None, 2, 50)        0           ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            " lstm_18 (LSTM)                 (None, 64)           29440       ['reshape_11[0][0]']             \n",
            "                                                                                                  \n",
            " dense_41 (Dense)               (None, 10)           650         ['lstm_18[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,261,190\n",
            "Trainable params: 8,261,190\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}